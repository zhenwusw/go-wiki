# 爬虫框架的设计和实现

## 功能需求和分析

网络爬虫框架会反复地执行如下步骤直至触碰到停止条件。

* 网页下载器
* 请求引擎
* 分析器
* 条目和条目处理管道
* 调度器

![image](https://cloud.githubusercontent.com/assets/349215/23584607/f290056a-01a0-11e7-8752-119e59b2dbae.png)

![image](https://cloud.githubusercontent.com/assets/349215/23585036/aa90ee66-01ad-11e7-85f4-ad1fc0d816f8.png)


## 模块设计

**网页下载器**

**请求引擎**

**分析器**

**条目和条目处理管道**

网络爬虫框架应该丝毫不关心这些条目会怎样被处理和持久化。它仅仅负责控制整体的处理流程。我们把负责单个处理步骤的程序称为条目处理器


与另外两个处理模块相比，条目处理管道是比较特殊的。顾名思义，它应该是以流式处理为基础的


**调度器**


调度器的主要职责是调度各个处理模块的运行。其中包括维护各个处理模块的实例、在不同的处理模块实例之间传递数据（请求、响应或条目），以及监控所有这些被调度者的状态，等等。



##  基本数据结构





---

* 判定有效网络地址
* 有效网络地址的边界定义和校验
* 重复的网络地址过滤


复杂的逻辑

* 不通网页需要不同的头信息和主题内容
* 对内容的筛选需要各种条件：提取、过滤、分类等




## 参考
[Go并发编程实战 - 郝林 | 豆瓣阅读](https://read.douban.com/reader/ebook/12187287/)

